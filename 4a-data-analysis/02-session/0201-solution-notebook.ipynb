{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0201 - Advanced EDA With Python - Solution Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Written by Alexandre Gazagnes\n",
    "* Last update: 2024-02-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have 2 options: \n",
    "- Locally: \n",
    "\n",
    "    - **Install Anaconda https://www.anaconda.com/ or Jupyter https://jupyter.org/install on your machine**\n",
    "\n",
    "    - Use Anaconda or Jupyter installed on the Unilasalle PC (**Warning âš ï¸**: some packages may be missing) \n",
    "\n",
    "\n",
    "- Online:\n",
    "\n",
    "    - **Use Google Colab https://colab.research.google.com/** (you have to be connected to your google account)\n",
    "\n",
    "    - **Open this notebook on Google colab URL**\n",
    "        * Badge\n",
    "\n",
    "    - Use Jupyter online  https://jupyter.org/try-jupyter (**Warning âš ï¸**: External packages cannot be installed) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material\n",
    "\n",
    "All the material for this course could be found here.\n",
    "- https://github.com/AlexandreGazagnes/Unilassalle-Public-Ressources/tree/main/4a-data-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're an export project manager for a major food manufacturer. \n",
    "\n",
    "You are in charge of poultry departement.\n",
    "\n",
    "You have been asked to identify countries within the company's database or using external datasets in order to target them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "After a quick look on the internet, you find a very interesting dataset on the FAO website. It contains a list of countries with various indicators. You decide to use this dataset to identify segments of countries.\n",
    "\n",
    "Find the data : \n",
    "    \n",
    "- **You can use a preprocessed version of the dataset [here](https://gist.githubusercontent.com/AlexandreGazagnes/28a8da40ffa339b96b02f3e3cd79792d/raw/4849eba0d69f43472a7637e1b62e56fd7eb09c7e/chicken.csv).** (Best option)\n",
    "\n",
    "- You can also download the \"raw\" dataset [here](https://www.fao.org/faostat/fr/#data/QCL). (**Warning âš ï¸** : You will have to preprocess the data before playing this notebook )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission\n",
    "\n",
    "Your objective is to : \n",
    "\n",
    "- Take a quick tour of the data to understand the data set \n",
    "\n",
    "- Clean up the dataset if necessary \n",
    "\n",
    "- Try to have a deep understanding of our market, using, PCA or MCA.\n",
    "\n",
    "- Perform clustering with Kmeans and Agglomerative Clustering, focusing on countries with large potential markets: populous countries, wealthy countries and/or countries with high import levels\n",
    "\n",
    "- You need to be able to understand and explain the clusters you've created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will display the system information:\n",
    "\n",
    "Uncomment theses lines if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will install the required packages:\n",
    "\n",
    "**Please note that if you are using google colab, all you need is already installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas matplotlib seaborn plotly scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will download the dataset:\n",
    "\n",
    "**Please note that we will download the dataset later, in this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/AlexandreGazagnes/28a8da40ffa339b96b02f3e3cd79792d/raw/4849eba0d69f43472a7637e1b62e56fd7eb09c7e/chicken.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     # DataFrame\n",
    "import numpy as np      # Matrix and advanced maths operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Graphical libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt     # Visualisation\n",
    "import seaborn as sns               # Visualisation\n",
    "# import plotly.express as px       # Visualisation (not used here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Machine Learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler            # Our Standardizer Obj.\n",
    "from sklearn.decomposition import PCA                       # Our PCA Obj. \n",
    "\n",
    "# for Later :\n",
    "# from sklearn.cluster import KMeans                        # Clustering\n",
    "# from sklearn.cluster import AgglomerativeClustering       # Clustering\n",
    "# from sklearn.metrics import silhouette_score              # Clustering\n",
    "# from sklearn.metrics import davies_bouldin_score          # Clustering\n",
    "# from sklearn.datasets import load_iris                    # Toy Dataset\n",
    "# from scipy.cluster.hierarchy import dendrogram, linkage   # Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning:**These imports must be done, it is not possible to use this notebook without pandas, matplotlib etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st option : Download the dataset from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gist.githubusercontent.com/AlexandreGazagnes/28a8da40ffa339b96b02f3e3cd79792d/raw/4849eba0d69f43472a7637e1b62e56fd7eb09c7e/chicken.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Option : Read data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or\n",
    "\n",
    "# fn = \"my/awsome/respository/my_awsome_file.csv\"\n",
    "# fn = \"./chicken.csv\"\n",
    "# df = pd.read_csv(fn)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head \n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the last rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample \n",
    "\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample with just 10% of the dataset \n",
    "\n",
    "df.sample(frac=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What data types are present in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtypes\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning: \n",
    "**Please note that we have here main python dtypes**\n",
    "Data types : \n",
    "- int : *Integer* : 1,2,12332, 1_000_000\n",
    "- float : *Float* : 1.243453, 198776.8789, 1.9776\n",
    "- object : In this example object stands for *String* : \"Paris\", \"Rouen\", \"Lea\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of columns with specific data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts on dtypes\n",
    "\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only string columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dtypes str\n",
    "\n",
    "df.select_dtypes(include='object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dtypes float\n",
    "\n",
    "df.select_dtypes(include=\"float\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of unique values : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number unique values for int columns\n",
    "\n",
    "df.select_dtypes(include=int).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number unique values for float columns\n",
    "\n",
    "df.select_dtypes(include=float).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number unique values for object columns\n",
    "\n",
    "df.select_dtypes(include=\"object\").nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many NaN are present in the dataset?\n",
    "\n",
    ":warning: **Please note that ```NaN``` stands for Not A Number aka ```Missing Value```***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna ?\n",
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of isna\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have some Missing values here ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look to a numercial summary of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe ? \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, hard to read...\n",
    "Let's try something better : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better ?\n",
    "df.describe().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tmp variable\n",
    "\n",
    "corr = df.select_dtypes(include=\"number\").corr()\n",
    "corr.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok ... Not so easy to read ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a first visualization of the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building heatmap \n",
    "\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good, we have to improve this visualisation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better heatmap ?\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt='.2f', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤Ÿ Great ! ... Do we have something better ? (better stands for *more readable*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best visualization for the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best heatmap ?\n",
    "mask = np.triu(corr)\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gona use this correlation matrix a lot. \n",
    "Maybe it is a good idea to create a function !   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your first function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b) : \n",
    "\n",
    "    return a+ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just add a triple quote ```\"\"\" Some usefull comment \"\"\"``` after the first line : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    \"\"\"This function make the addition of a and b and return the result\"\"\"\n",
    "\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to display the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a function\n",
    "\n",
    "def make_corr_heatmap(df):\n",
    "    \"\"\"Just compute and plot the correlation matrix with a fancy heat map \"\"\"\n",
    "\n",
    "    corr = df.select_dtypes(include=\"number\").corr()\n",
    "    mask = np.triu(corr)\n",
    "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":clap: Nice ! We will use this visualization a lot in this feature..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Boxplot to visualize the distribution of the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot\n",
    "sns.boxplot(data=df.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very unbalanced distribution with 2 outliers : China and India\n",
    "\n",
    "Please note that China do not have 1.4 million citizens but 1.4 BILLION. So we need to fix this (later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘©â€ðŸŽ“ Just as fun fact, we can use the log trasnformation to *fix* this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to apply log transformation to the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = np.log(df.population)\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the box plot of our new feature : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":clap: Great ! \n",
    "\n",
    "Let's try an other implementation (same result) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.log1p(df.population)  # Here np.log1p(my_feature) == np.log(1 + my_feature)\n",
    "sns.boxplot(data=tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Why ```log(my_feature + 1 )``` ?\n",
    "\n",
    "Imagine all the people ... like John Lenon... or better ! Imagine NO PEOPLE, 0 for the population of one country...\n",
    "\n",
    "What is the output of ```np.log(0)``` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df.select_dtypes(include=\"number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot each numerical column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a pairplot of the numerical columns:\n",
    "\n",
    "â²ï¸ This visualization can be slow with large datasets. \n",
    "\n",
    "Use ```VIZ = True / False``` to enable / disable the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIZ = True # Enable this with True\n",
    "if VIZ : \n",
    "    sns.pairplot(df.select_dtypes(exclude=\"object\"), corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look to small countries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population.describe().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the population with the good number : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population = df.population.astype(int) * 1_000\n",
    "df.population.describe().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the dataset by population : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"population\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"population\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only \"large\" countries +1M : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here ```1000000``` is not so easy to read.\n",
    "\n",
    "With python, we can use the ```_``` special character in order to separate\n",
    "thousands :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to find rows with pop > threshold : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.population > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a tmp (temporary) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexor = df.population > threshold\n",
    "indexor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this ```bool``` vector (True / False) as a selector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[indexor]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can write all this code in a single line : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.population > 1_000_000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our new DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"population\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok why not, but let's try a new threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only \"large\" countries +5M : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5_000_000\n",
    "df = df.loc[df.population > threshold]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"population\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our correlation matrix : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"code_zone\",\n",
    "    \"zone\",\n",
    "    \"dispo_int\", # WHY NOT\n",
    "    \"import\",\n",
    "    # \"dispo_prot\",\n",
    "    \"dispo_alim\",\n",
    "    \"export\",\n",
    "    # \"residus\",\n",
    "    # \"var_stock\",\n",
    "    # \"prod\",\n",
    "    # \"nourriture\",\n",
    "    \"population\",\n",
    "]\n",
    "\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the selection : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.loc[ : , cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column with some kind of \"depedency\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dependency\"] = df[\"import\"] / df[\"dispo_int\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the dataframe by dependency : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"dependency\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"dependency\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have any country with a ```0``` value for ```dispo_int```` ? \n",
    "\n",
    "So we need to clean ```0``` values for ```dispo_int```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with infini values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.dispo_int > 0]\n",
    "df.sort_values(\"dispo_int\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop useless columns if needed : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.drop(columns=[\"code_zone\"], errors=\"ignore\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute diffrence between columns Import and Export : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Import - Export\n",
    "# Create new column name delta\n",
    "\n",
    "df[\"delta\"] = df[\"import\"] - df[\"export\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the correlation matrix : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export is no more needed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"export\", inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last print of our df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last print of our df\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to standardize our dataset, ie transform it to have 0.0 as mean\n",
    "and 1.0 as std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only numerical columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning:**Using ```X``` here is a very strong convention applied by any data analyst, scientist etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df.select_dtypes(include=\"number\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init a ```scaler``` object from the ```StandardScaler``` class of scikit-learn : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  StandardScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit this object, ie *precompute* the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, do transform our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please not that we can perform fit and transform in the same operation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual... not so easy to read. \n",
    "\n",
    "The have a ```np.ndarray``` oject, and the output is pretty uggly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“¢ We can use the ```type``` function of python to have an idea of the data type of ```X_scaled```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a DataFrame with the scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data were scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can compute this transformation manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = (X - X.mean()) / X.std()\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ˜‡ Ok, this implementation is better ! \n",
    "\n",
    "But we have used a ```StandardScaler``` for educational purpose : regarding OOP, regarding how to manage a scikit-learn object etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a PCA : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our new dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = pca.transform(X_scaled)\n",
    "X_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, ```X_proj``` is a strong convention**\n",
    "\n",
    "Same problem than with X_scaled : Not so easy to read.\n",
    "\n",
    "Same problem ? Same solution! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to create a DataFrame : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About the columns names\n",
    "\n",
    "cols = [\"PC1\", \"PC2\", \"PC3\", \"PC4\",\t\"PC5\", \"PC6\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out new X_proj : \n",
    "\n",
    "X_proj = pd.DataFrame(X_proj, columns=cols)\n",
    "X_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that a better implementation of our columns list is possible : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f\"PC{i}\" for i in range(1, pca.n_components_ + 1)]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our components : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pca.components_\n",
    "pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a data Frame  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.DataFrame(pcs, \n",
    "                          columns=X.columns, \n",
    "                          index=cols)\n",
    "components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompute the first value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value  = X_proj.iloc[0, 0]\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st line of X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute our value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (-0.3724 * 0.66)\n",
    "    + (-0.4424 * 0.11)\n",
    "    + (-1.090 * 0.34)\n",
    "    + (-0.1587 * 0.46)\n",
    "    + (0.4643 * -0.1)\n",
    "    + (0.1057 * -0.46)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```0.66```, ```0.11``` ... come from our components : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insead of using an uggly sum, we can use just one line of code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i * j for i, j in zip(pcs[0], X_scaled.iloc[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just transpose this dataframe (Swap columns and rows for better readability) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = components.T\n",
    "components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a Heatmap :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(components, cmap=\"coolwarm\", vmax=1, vmin=-1, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained variance ratio is pre-computed by scikit-learn : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(y=pca.explained_variance_ratio_, \n",
    "             x=components.columns, \n",
    "             marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better feature here is the cumulative variance : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_var = pca.explained_variance_ratio_.cumsum()\n",
    "cum_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = components.columns.tolist()\n",
    "y = cum_var.tolist()\n",
    "sns.lineplot(y=y, x=x, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just add ```PC0``` with a fake ```0``` value to improve our visualization : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"PC0\"] + components.columns.tolist()\n",
    "y = [0] + cum_var.tolist()\n",
    "sns.lineplot(y=y, x=x, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_graph(\n",
    "    X_scaled,\n",
    "    pca,\n",
    "    dim: list = [0, 1],\n",
    "):\n",
    "    \"\"\"Display the correlation graph for a PCA\n",
    "\n",
    "    Positional arguments :\n",
    "        - X_scaled : DataFrame | np.array : the scaled dataset \n",
    "        - pca : PCA : a PCA instance already fitted\n",
    "\n",
    "    Optional arguments :\n",
    "        - dim : list or tuple : values x,y for the dimensions (PC) to plot.\n",
    "            default :  [0,1] stands for F1, F2 \"\"\"\n",
    "\n",
    "    # Extract x et y\n",
    "    x, y = dim\n",
    "\n",
    "    # Features\n",
    "    features = X_scaled.columns\n",
    "\n",
    "    # Fig size (inches)\n",
    "    fig, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "    # For each component :\n",
    "    for i in range(0, pca.components_.shape[1]):\n",
    "        # Les flÃ¨ches\n",
    "        ax.arrow(\n",
    "            0,\n",
    "            0,\n",
    "            pca.components_[x, i],\n",
    "            pca.components_[y, i],\n",
    "            head_width=0.07,\n",
    "            head_length=0.07,\n",
    "            width=0.02,\n",
    "        )\n",
    "\n",
    "        # Labels\n",
    "        plt.text(\n",
    "            pca.components_[x, i] + 0.05,\n",
    "            pca.components_[y, i] + 0.05,\n",
    "            features[i],\n",
    "        )\n",
    "\n",
    "    # Display horizontal and vertical lines\n",
    "    plt.plot([-1, 1], [0, 0], color=\"grey\", ls=\"--\")\n",
    "    plt.plot([0, 0], [-1, 1], color=\"grey\", ls=\"--\")\n",
    "\n",
    "    # Axes names with % of inertia\n",
    "    plt.xlabel(\n",
    "        \"F{} ({}%)\".format(\n",
    "            x + 1, round(100 * pca.explained_variance_ratio_[x], 1)\n",
    "        )\n",
    "    )\n",
    "    plt.ylabel(\n",
    "        \"F{} ({}%)\".format(\n",
    "            y + 1, round(100 * pca.explained_variance_ratio_[y], 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Title     \n",
    "    plt.title(\"Cercle des corrÃ©lations (F{} et F{})\".format(x + 1, y + 1))\n",
    "\n",
    "    # Draw the circle\n",
    "    an = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.plot(np.cos(an), np.sin(an))  # Add a unit circle for scale\n",
    "\n",
    "    # Axes and final display\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a first correlation graph (PC1 v PC2) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_graph(\n",
    "    X_scaled,\n",
    "    pca,\n",
    "    dim = [0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a 2nd correlation graph (PC2 v PC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_graph(\n",
    "    X_scaled,\n",
    "    pca,\n",
    "    dim=[0, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a 2nd correlation graph (PC1 v PC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_graph(\n",
    "    X_scaled,\n",
    "    pca,\n",
    "    dim=[1, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorial planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial_planes(\n",
    "    X_,\n",
    "    pca,\n",
    "    dim : list = [0, 1],\n",
    "    labels: list = None,\n",
    "    clusters: list = None,\n",
    "    figsize: list = [12, 10],\n",
    "    fontsize = 14,\n",
    "):\n",
    "\n",
    "    \"\"\"Display the Factorial plane projection of our data\n",
    "\n",
    "    Positional arguments :\n",
    "        - X_ : DataFrame | np.array : the scaled dataset\n",
    "        - pca : PCA : a PCA instance already fitted\n",
    "\n",
    "    Optional arguments :\n",
    "        - dim : list or tuple : values x,y for the dimensions (PC) to plot.\n",
    "            default :  [0,1] stands for F1, F2\n",
    "        - labels : list or tuple or None: labels of our data such as countrie's name for instance\n",
    "        - clusters : list or tuple or None : clusters of our data such as 'A', 'B', 'C' for instance\n",
    "        - figsize : list or tuple : The size in inches of our visualisation\n",
    "            default : [12, 10]\n",
    "        - fontsize : int  : The fontsize of our labels.\n",
    "            default : 14\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract dimensions\n",
    "    x, y = dim\n",
    "\n",
    "    # Manage dtypes errors\n",
    "    dtypes = (pd.DataFrame, np.ndarray, pd.Series, list, tuple, set)\n",
    "    if not isinstance(labels, dtypes):\n",
    "        labels = []\n",
    "    if not isinstance(clusters, dtypes):\n",
    "        clusters = []\n",
    "\n",
    "    # Fig size\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    # Display cluster with specific color IF NEEDED\n",
    "    if len(clusters):\n",
    "        sns.scatterplot(data=None, x=X_[:, x], y=X_[:, y], hue=clusters)\n",
    "    else:\n",
    "        sns.scatterplot(data=None, x=X_[:, x], y=X_[:, y])\n",
    "\n",
    "    # Display explained variance ratio\n",
    "    v1 = str(round(100 * pca.explained_variance_ratio_[x])) + \" %\"\n",
    "    v2 = str(round(100 * pca.explained_variance_ratio_[y])) + \" %\"\n",
    "\n",
    "    # Axes name, with % of explained inertia\n",
    "    ax.set_xlabel(f\"F{x+1} {v1}\")\n",
    "    ax.set_ylabel(f\"F{y+1} {v2}\")\n",
    "\n",
    "    # Values for x max et y max\n",
    "    x_max = np.abs(X_[:, x]).max() * 1.1\n",
    "    y_max = np.abs(X_[:, y]).max() * 1.1\n",
    "\n",
    "    # Set limits for x and y\n",
    "    ax.set_xlim(left=-x_max, right=x_max)\n",
    "    ax.set_ylim(bottom=-y_max, top=y_max)\n",
    "\n",
    "    # Display horizontal and vertical lines\n",
    "    plt.plot([-x_max, x_max], [0, 0], color=\"grey\", alpha=0.8)\n",
    "    plt.plot([0, 0], [-y_max, y_max], color=\"grey\", alpha=0.8)\n",
    "\n",
    "    # Labels and dots\n",
    "    if len(labels):\n",
    "        for i, (_x, _y) in enumerate(X_[:, [x, y]]):\n",
    "            plt.text(\n",
    "                _x, _y + 0.05, labels[i], fontsize=fontsize, ha=\"center\", va=\"center\"\n",
    "            )\n",
    "\n",
    "    # Title and final display\n",
    "    plt.title(f\"Projection des individus (sur F{x+1} et F{y+1})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a basic factorial plane : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorial_planes(X_proj.values, pca, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a factorial plane with size and labels : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorial_planes(X_proj.values, pca, [0, 1], \n",
    "                 labels=df.zone.values, \n",
    "                 figsize=(20, 16), \n",
    "                 fontsize=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
