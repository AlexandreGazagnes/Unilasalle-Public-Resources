---
marp: true
paginate: true
# theme: default
theme: gaia
---

# Data Analysis and Decision Making

<br>
<br>

<div style="text-align: center;">
  <img src="./img/image-13.png" alt="Mesopotamian Trade Records" style="max-width: 80%;">
</div>

<br>
<br>

<div style="text-align: center;">
  4th Year - Data Analysis - 2025
</div>

<br>

<div style="text-align: center;">
  Alexandre Gazagnes
</div>

---

## 1. Introduction to  -- *REAL* -- Data Analysis

### 1.1 A Brief History of the Data Revolution

#### 1.1.1 From Writing to the Internet

---



1. **Writing Invention - Mesopotamia**: The earliest form of data recording—cuneiform tablets used to track trade, taxes, and inventories.

<div style="text-align: center;">
  <img src="./img/image.png" alt="Mesopotamian Trade Records" style="max-width: 80%;">
</div>


---

2. **Gutenberg’s Printing Press**: Made books accessible, empowering the spread of knowledge and enhancing religious and political influence.

<div style="text-align: center;">
  <img src="./img/image-6.png" alt="Cuneiform " style="max-width: 80%;">
</div>


---

3. **Telegraph / Phone**: Instant communication across distances revolutionized commerce and personal connectivity. 
<div style="text-align: center;">
  <img src="./img/image-5.png" alt="Telegraph and Morse Code " style="max-width: 80%;">
</div>

---

4. **The Internet**: The advent of websites, email, and social media made data ubiquitous, driving modern global 
communication and business.

<div style="text-align: center;">
  <img src="./img/image-4.png" alt="Internet Revolution" style="max-width: 80%;">
</div>


---

#### 1.1.2 Data as a Source of Power and Wealth

- **Data → Insight → Decision → Value**:
   - Analyze situations and options.
   - Make informed decisions.
   - Drive actions that generate power and wealth.

   ---

- **The Double-Edged Sword**:
   - Wrong data can lead to successful outcomes by luck.
   - Good data and analysis might fail due to unforeseen circumstances.

---

#### 1.1.3 Short Stories from Data History

1. **Mesopotamian Trade Records**: Early accounting systems to track wealth.

<div style="text-align: center;">
  <img src="./img/image.png" alt="Mesopotamian Trade Records" style="max-width: 80%;">
</div>

---

2. **Domesday Book (England)**: Commissioned by William the Conqueror to assess land and taxes.

<div style="text-align: center;">
  <img src="./img/image-1.png" alt="Domesday Book (England)" style="max-width: 80%;">
</div>

--- 

3. **Nurse in Wartime**: Florence Nightingale’s use of data visualization to highlight sanitary conditions over battlefield injuries.


<div style="text-align: center;">
  <img src="./img/image-2.png" alt="Florence Nightingale’s Data Visualization" style="max-width: 80%;">
</div>

--- 

4. **London Cholera Epidemic**: John Snow’s mapping of cholera clusters linked to contaminated water sources.

<div style="text-align: center;">
  <img src="./img/image-3.png" alt="London Cholera Epidemic" style="max-width: 80%;">
</div>

---

## 1.2 Misinterpretations of Data

#### 1.2.1 WWII Plane Armor

<div style="text-align: center;">
  <img src="./img/image-7.png" alt="WWII Plane Armor" style="max-width: 80%;">
</div>

---
<br>
<br>
<br>

- Observing bullet holes on returning planes led to the assumption armor should be placed there.

- **The Insight**: Focus on parts where planes didn’t sustain damage but were still crucial to survival—the non-returned planes provided key missing data.

---

#### 1.2.2 Being Fooled by Data:
- Common cognitive biases:
   - **Confirmation Bias**: Seeking data that confirms existing beliefs.
   - **Availability Heuristic**: Overvaluing easily accessible information.
   - **Survivorship Bias**: Focusing on successful outcomes while ignoring failures.
   - **Loss Aversion**: Overvaluing potential losses over gains.
   - **Sunk Cost Fallacy**: Justifying continued investment in a failing endeavor.
   - **Anchoring**: Relying too heavily on the first piece of information.

---

#### 1.2.3 Occam's Razor:

<br>
<br>
<div style="text-align: center;">
  <img src="./img/image-8.png" alt="Occam's Razor" style="max-width: 80%;">
</div>

---

<br>
<br>
<br>

- "The simplest explanation is usually the best." MISSUNDERSTOOD 
- Be cautious of convoluted interpretations.
- Simplest theory are always easiest to refute 

---


#### 1.2.4 Spurious Correlations and Hidden Variables

<div style="text-align: center;">
  <img src="./img/image-9.png" alt="Spurious Correlations" style="max-width: 80%;">
</div>

<br>

https://www.tylervigen.com/spurious-correlations

---

<br>
<br>
<br>
<div style="text-align: center;">

Correlation but no causation 

<br>

Correlation but no causation 

<br>

Correlation but no causation 

</div>

<!-- --- -->

<!-- #### Example 2: Smoking and Speed

- Data suggested smokers are faster, but the hidden variable was **age** (younger individuals smoked more and were faster).
- Other hidden variables include gender, socioeconomic status, and education. -->

---

#### 1.2.5 Famous Data Misunderstanding


<br>
<br>
<div style="text-align: center;">
  <img src="./img/image-10.png" alt>
</div>

--- 

* A shark attack in a small town.
* Mayor worried about the business.
* Major operation to kill **THE** shark, Shark was killed! 
* Mayor says "We're done with **THE** shark"
* Scientist says "We're not done with **THE** shark, We're done  with **ONE** shark"
* Mayor says "Come on, fool, stop with your science, we killed **THE** shark."
* Scientist says, let me show you **THE** data, we're not done with **THE** shark, we're done with **ONE** shark"

---

### 1.3 Living in a Post-Truth World

#### 1.3.1 Somes stories false but not critical

<br> 

<div style="text-align: center;">
  <img src="./img/image-11.png" alt="Coca-Cola Santa Claus" style="max-width: 80%;">

--- 

#### 1.3.2 Somes stories false and critical

<br>
<div style="text-align: center;">
    <img src="./img/image-12.png" alt="fake footage" style="max-width: 80%;">
</div>


--- 


50% of the population at least "not" sure in US Gen Z

<div style="text-align: center;">
  <img src="./img/image-14.png" alt="fake footage" style="max-width: 80%;">
</div>

---

### 1.3.3 Somes "conspiracies" migh be true 

Colin Powell, 2003, UN, "blufing" like pro poker player : 

<br>
<br>

<div style="text-align: center;">
  <img src="./img/image-15.png" alt="fake footage" style="max-width: 90%;">
</div>



--- 

#### 1.3.4 New challenges for everyone

<br>
<br>
   
- Where is THE truth ?

- AI-generated videos and audio clips can manipulate reality.

- Tons of short videos, generated by IA with huge click rate

- Origanized farms to generate fake news and manipulate public opinion


---

### 1.4 Conclusion

<br>
<br>
By understanding the power of data, historical lessons, and the risks of misinterpretation, we can develop a more informed, critical approach to decision-making in a data-driven world.


---



## 2. Not so Basic Reminder about Not so Basic Data Analysis

---

### 2.1 Data is not about mean, IQ or stat test?

<br>
<br>
<br>
<div style="text-align: center;">

No  
No  
No  
No

</div>

---

<br>

**Data → Insight → Decision → Value**  

<br>

Think in reverse:

- What is my purpose?
  - Optimizing **n**, finding solutions.
  - Business, money, medical goals.

- What is my problem?
- **What do I know about my problem?**

---

### 2.2 Getting Some Relevant Data

<br>
<br>

- What data might/should I want?
- Where to find it?
- What variables could I find (internet/open data/in my company)?
- Is it relevant? Too old? Too many? Trustable? Related?

---


### 2.3 Being Critical with Data

- How many variables are there?
- Can I trust them?

<br>

Examples:
- User database: someone listed as 198 years old?
- Many users 1750m tall? (Maybe data is in cm, in mm?)
- dataset with 95% of missing values?

---

### 2.4 First Look at the Data

#### 2.4.1 Reading the Data

- **Display the Data**:
  - Top 10 rows
  - Last 10 rows
  - Random 10 rows

- **Shape of the Data**
---

<br>
<br>
<div style="text-align: center;">

  **Take the time to look at the data**

<br>
<br>

  **Let your brain make some inferences (it’s pretty good at this)**

</div>

---

#### 2.4.2 Data Types and First Insights

- **Data Types**:
  - Numerical:
    - Continuous
    - Discrete

  - Categorical:
    - Ordinal
    - Cardinal

**Tip**: Convert ordinal categorical data to numerical if needed.

---


### 2.5 Missing Values and Outliers

- **Identify Missing Values**:
  - Count NaN values.
  - Missing values (%) by row/column.

- **Examine Outliers**:
  - Min / Max values.
  - Use summary stats and visualizations:
    - Mean / Standard Deviation / Density Function
    - Median / IQR / Box Plots

---

### 2.6 Preparing / cleaning the data

* Drop columns / lines with too many missing values
* Select subset of columns / lines with relevant data for  your analysis
* Fill missing values with mean, median, mode, or other values if relevant
* Transform categorical ordinal data into numerical data if relevant
* Apply log, square root, or other transformations to numerical data if relevant
* Remove outliers if relevant
* Create new columns if relevant

--- 

### 2.7 Univariate Analysis

#### 2.7.1 Numerical Data

- Descriptive statistics.
    - Mean / Standard Deviation / Density Function
    - Median / IQR / Box Plots

 
<br>
<br>

**Difference between mean and median?**

---



<div style="text-align: center;">
  <img src="./img/image-16.png" alt="Histograms" style="max-width: 60%;">
</div>

- Graphs:
  - Box Plots
  - Density Distributions

---

### 2.7.2 Categorical Data

- Descriptive statistics.
  - Count of categories.
  - Percentages per category.

- Graphs:
  - Bar Plot
  - Pie Chart


---

### 2.8 Bivariate/Mulivariate Analysis


### 2.8.1 Bivariate Analysis

- **Numerical vs. Numerical**:
  - Scatter Plots
  - Correlation Coefficient


- **Categorical vs. Numerical**:
    - Box Plots
    - Violin Plots
    - ANOVA

---

- **Categorical vs. Categorical**:
    - Contingency Tables
    - Chi-Square Test


<div style="text-align: center;">
  <img src="./img/image-17.png" alt="Bivariate Analysis" style="max-width: 80%;">
</div>

---


### 2.8.2 Multivariate analysis

Correlation matrix : 
* Heatmap
* Scatter plot matrix

Question to ask :

- What are the most correlated variables ?
- What does that mean to  have 2 variables very highly correlated ?
- What not so easy to interpret variables do  we have ?

---

## 3. Grouping Data & dimensions

--- 

### 3.1 Curse of dimentionality


In data : 
* More columns = more data = more information
* More columns = more data = more noise

**The more columns you have, the more difficult it is to find the signal in the noise**

Data selection is key to avoid the curse of dimentionality

--- 

Having 100 or 1000 columns is a garantee of having a good dataset ? 

<br>
<br>

<div style="text-align: center;">
  <img src="./img/image-18.png" alt="Dimentionality Reduction" style="max-width: 130%;">   
</div>

Do you really need all of them ?

---

## 3.2 Main ideas behind Grouping Data & dimensions


1. **Reduces Complexity**

    High-dimensional data can be difficult to analyze due to the "curse of dimensionality." Reducing dimensions simplifies data, making it easier to understand and process.

2. **Enhances Visualization**

    Dimensionality reduction techniques like PCA (Principal Component Analysis) or t-SNE reduce data to 2D or 3D, enabling visualization of complex datasets.

---

3. **Facilitates Interpretability** 

    A dataset with fewer dimensions is easier to interpret and analyze. It highlights the most important variables contributing to the underlying patterns.

3. **Improves Performance**

    Algorithms like clustering, regression, or classification perform faster on lower-dimensional data. Computational efficiency increases, especially for machine learning models.

--- 


<br>


**Grouping Data & dimensions  : 2 main techniques** 

<br>

- Reducing the number of columns ==> ACP /PCA : Principal Component Analysis

<br>

- Reducing the number of lines  ==> clustering : K-means / DBSCAN / Hierarchical clustering

---

### G3.3 "Grouping the columns" with Principal Component Analysis 


- **ACP /PCA : Principal Component Analysis**

    - **Goal**: Reduce the number of dimensions while retaining the most important information.
    - **Method**: Linear transformation to create new uncorrelated variables (principal components).
    - **Applications**: Data visualization, noise reduction, feature extraction, and data compression.

--- 

**Process** 

* Prepare the  data by  standardizing it.
* Computing Explain variance ratio.
* Selecting the number of components.
* Computing new synthetic variables.
* Interpreting the new synthetic variables.
* Transforming the data.
* Projetcion of the  data in the new synthetic variables.
* Analysing the results.

---

Raw data : 

<br>

<div style="text-align: center;">
  <img src="./img/image-19.png" alt="ACP" style="max-width: 80%;">
</div>

---

Standardized data :

<div style="text-align: center;">
  <img src="./img/image-20.png" alt="ACP" style="max-width: 80%;">
</div>

---

New dimensions : 

<br>

<div style="text-align: center;">
  <img src="./img/image-22.png" alt="ACP" style="max-width: 80%;">
</div>

---

Explained variance ratio : 

<br>

<div style="text-align: center;">
  <img src="./img/image-21.png" alt="ACP" style="max-width: 80%;">
</div>

--- 

Correlation between the new dimensions and the old ones :


<br>

<div style="text-align: center;">
  <img src="./img/image-23.png" alt="ACP" style="max-width: 80%;">
</div>

---

Projection of the data in the new dimensions :

<br>

<div style="text-align: center;">
  <img src="./img/image-24.png" alt="ACP" style="max-width: 80%;">
</div>


--- 

### 3.4 "Grouping the lines" with clustering : K-Means

- **K-means** 

    - **Goal** : Group data points into clusters based on similarity, minimizing the variance within each cluster.
    
    - **Method** : Iteratively assigns data points to the nearest cluster centroid and updates centroids to minimize within-cluster variance.
    
    - **Applications** : Customer segmentation, anomaly detection, pattern recognition, and document clustering.


--- 

**Process**

* Prepare the data by normalizing or scaling it.
* Choose the number of clusters (k) based on prior knowledge or methods like the Elbow Method.
* Initialize the centroids randomly or using optimized techniques.
* Assign data points to the nearest centroid using a distance metric.
* Process data until convergence (when centroids no longer change significantly).
* Analyze the results:   Evaluate cluster quality, Plot, Interpret clusters in the context of the problem domain.


---

Running the Kmeans : 

<br>


<div style="text-align: center;">
  <img src="./img/image-27.png" alt="K-means" style="max-width: 80%;">
</div>

--- 

Assigning letters to  the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-28.png" alt="K-means" style="max-width: 80%;">
</div>

---

Displaying the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-26.png" alt="K-means" style="max-width: 80%;">
</div>

--- 

Using Box plot to evaluate the quality of the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-25.png" alt="K-means" style="max-width: 80%;">
</div>

--- 


Using Box plot to evaluate the quality of the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-29.png" alt="K-means" style="max-width: 80%;">
</div>


--- 

Using Box plot to evaluate the quality of the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-30.png" alt="K-means" style="max-width: 80%;">
</div>


--- 

Using Box plot to evaluate the quality of the clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-31.png" alt="K-means" style="max-width: 80%;">
</div>


--- 

About our groups : 

<br>

<div style="text-align: center;">
  <img src="./img/image-32.png" alt="K-means" style="max-width: 80%;">
</div>



--- 

About our groups : 

<br>
<div style="text-align: center;">
  <img src="./img/image-33.png" alt="K-means" style="max-width: 80%;">
</div>


--- 

About our groups : 

<br>

<div style="text-align: center;">
  <img src="./img/image-34.png" alt="K-means" style="max-width: 80%;">
</div>

<div style="text-align: center;">
  <img src="./img/image-35.png" alt="K-means" style="max-width: 80%;">
</div>



--- 

Conclusion 

<div style="text-align: center;">

| Feature       | Cluster A | Cluster C   | Cluster x   |
|---------------|-----------|-------------|-------------|
| dispo int     | =         |             |      ?      |
| import        | --        | - (-)       |      ?      |
| dispo alim    | --        | +           |      ?      |
| pop           | ++        | =           |      ?      |
| dependance    | --        | --          |      ?      |
| delta         | ++        | ++          |      ?      |
| dispo alim (modified) |   | + (+)       |      ?      |

</div>


--- 

### Clustering is about  making consistent groups of data points.

Simple example in a 2d space : 
<br>
<div style="text-align: center;">
  <img src="./img/image-36.png" alt="K-means" style="max-width: 80%;">
</div>

--- 
### How to define a good clustering ? 

* Maximising extra-cluster variance
* Minimising intra-cluster variance

<div style="text-align: center;">
  <img src="./img/image-37.png" alt="K-means" style="max-width: 80%;">
</div>



--- 

#### How defining a good number of clusters ? 

About The elbow method : 
* Finding the elbow in the curve of the intra-cluster variance

<div style="text-align: center;">
  <img src="./img/image-38.png" alt="K-means" style="max-width: 80%;">
</div>




---

Computing Within-cluster variance for different number of clusters :

<br>

<div style="text-align: center;">
  <img src="./img/image-39.png" alt="K-means" style="max-width: 80%;">
</div>

---

Displaying the elbow :

<br>

<div style="text-align: center;">
  <img src="./img/image-40.png" alt="K-means" style="max-width: 80%;">
</div>


---

## 4 Python and Data Analysis 

---

### 4.1 Why Python for Data Analysis?



Python is the best candidate : 
* Easy to learn
* Huge community
* Many libraries
* Many tools 
* Used in many fields IRL


---

### 4.2 Using Python for Data Analysis

 

<!-- You have 2 options: 
- Locally: 

    - **Install Anaconda https://www.anaconda.com/ or Jupyter https://jupyter.org/install on your machine**

    - Use Anaconda or Jupyter installed on the Unilasalle PC (**Warning ⚠️**: some packages may be missing) 


--- -->

- Online:

    - **Use Google Colab https://colab.research.google.com/** (you have to be connected to your google account)

    <!-- - **Open this notebook on Google colab URL**
        * Badge -->


    - Use Jupyter online  https://jupyter.org/try-jupyter (**Warning ⚠️**: External packages cannot be installed) 


---


### 4.3 Material

All the material for this course could be found here.
- https://github.com/AlexandreGazagnes/Unilassalle-Public-Ressources/tree/main/4a-data-analysis

External ressources : 


- On Youtube : 
    - https://www.youtube.com/watch?v=8KeJZBZGtYo
    - https://www.youtube.com/watch?v=JJYZ3OE_lGo
    - https://www.youtube.com/watch?v=tCVXoTV12dE


---

- On Youtube : 
    - https://www.youtube.com/watch?v=ovlID7gefzE
    - https://www.youtube.com/watch?v=IMrxB8Mq5KU
    - https://www.youtube.com/watch?v=Ou-7G9VQugg
    - https://www.youtube.com/watch?v=5pf0_bpNbkw

---

### 4.4 Context of  the pratical work


<br>

You are a new employee of the NPO named "NPO".

You are in charged of data analysis.

First project is about GHG emissions, more precisely regarding Bovine Meat.


--- 

### 4.5 Data

After a quick look on the internet, you find a very interesting dataset on the FAO website. It contains a list of various indicators. You decide to use this dataset to identify segments of countries.

- Find relevant data : 
    - https://www.kaggle.com/datasets/unitednations/global-food-agriculture-statistics
    - https://www.kaggle.com/datasets/dorbicycle/world-foodfeed-production
    - https://www.fao.org/faostat/en/
    - https://fr-en.openfoodfacts.org/
    - https://fr-en.openfoodfacts.org/data


--- 

<br>
<br>
<br>
<br>


**You can use a preprocessed version of the dataset [here](https://gist.githubusercontent.com/AlexandreGazagnes/2000e5c0e9149ffdb8c682a751ac448a/raw/35ad83320c26155415b7cccff8a4150ee80ee501/FAO_Unilassalle_raw.csv).** (Best option)


---

### 4.6 Mission 


Our job is to : 
* Prepare notebook environment
* Load data / Explore data
* Clean data ==> Select relevant data
* Clean data ==> Handle missing values
* Clean data ==> Handle duplicates ?  / Handle outliers ?
* Perform some basic analysis and data inspection
* Perform some basic visualisation
* Export our data

--- 

### 4.7 Time To practice !  



* Let's Go ! 